---
title: "pi0.5"
date: 2025-12-29 00:15:18
tags: ["25", "12"]
author: "Julyfun M4"
os: "Darwin tutianpeikeladeMac-mini.local 24.3.0 Darwin Kernel Version 24.3.0: Thu Jan  2 20:22:58 PST 2025; root:xnu-11215.81.4~3/RELEASE_ARM64_T8132 arm64"
assume-you-know: [computer]
confidence: 2
---

```
  π₀.₅ (Pi0.5) 模型架构

  基于代码库的分析，π₀.₅ 是一个基于流匹配的视觉-语言-动作模型，是 π₀ 的升级版本，具有更好的开放世界泛化能力。

  核心架构图

  ┌─────────────────────────────────────────────────────────────────────────┐
  │                        π₀.₅ 模型架构 (Pi0.5)                            │
  └─────────────────────────────────────────────────────────────────────────┘

  输入层
  ├─────────────────────────────────────────────────────────────────────┤
  │ 前缀 - 上下文编码                                                     │
  │ ├─ 多视角图像                                                         │
  │ │  ├─ base_0_rgb (224×224×3) - 基础相机视角                        │
  │ │  ├─ left_wrist_0_rgb (224×224×3) - 左腕相机视角                  │
  │ │  └─ right_wrist_0_rgb (224×224×3) - 右腕相机视角                 │
  │ ├─ 语言指令                                                          │
  │ │  └─ tokenized_prompt (最大 200 tokens) - 离散语言标记             │
  │ └─ 状态表示                                                          │
  │    └─ state (32-dim) - **作为离散语言标记处理** (π₀.₅ 特点)         │
  │                                                                       │
  │ 后缀 - 动作生成                                                       │
  │ ├─ 带噪声动作 (noisy_actions) - 流匹配输入                          │
  │ ├─ 时间步嵌入                                                         │
  │ │  └─ timestep ∈ [0.001, 0.999] - 正弦-余弦位置编码                 │
  │ └─ **adaRMSNorm 条件** (π₀.₅ 特点)                                  │
  └─────────────────────────────────────────────────────────────────────┘
                      ↓
  视觉编码器
  ├─────────────────────────────────────────────────────────────────────┤
  │ SigLIP Vision Tower (So400m/14)                                      │
  │ ├─ 2D sincos 位置编码                                                │
  │ ├─ Vision Transformer 处理                                          │
  │ └─ 输出维度: PaliGemma width (取决于 gemma_2b 变体)                 │
  └─────────────────────────────────────────────────────────────────────┘
                      ↓
  双专家语言模型
  ├─────────────────────────────────────────────────────────────────────┤
  │ PaliGemma Dual Experts (基于 Gemma 架构)                           │
  │                                                                       │
  │ 专家 1: PaliGemma 专家 (gemma_2b)                                   │
  │ ├─ 主要语言理解和视觉-语言融合                                       │
  │ ├─ 处理图像和语言输入                                                │
  │ └─ **不使用 adaRMSNorm**                                            │
  │                                                                       │
  │ 专家 2: 动作专家 (gemma_300m)                                       │
  │ ├─ 专门用于动作预测                                                  │
  │ ├─ 使用 **adaRMSNorm** 注入时间步条件 (π₀.₅ 特点)                   │
  │ └─ 接收动作+时间混合表示                                            │
  └─────────────────────────────────────────────────────────────────────┘
                      ↓
  动作输出投影
  ├─────────────────────────────────────────────────────────────────────┤
  │ Action Projection Layer                                             │
  │ ├─ Linear: action_expert.width → action_dim (32)                    │
  │ └─ 输出: 清洁动作 v_t (去噪后的速度场)                              │
  └─────────────────────────────────────────────────────────────────────┘

  π₀.₅ 与 π₀ 的关键区别

  | 特性          | π₀                            | π₀.₅                     |
  |-------------|-------------------------------|--------------------------|
  | 状态输入方式      | 连续状态 token (单独的 suffix token) | 离散语言标记 (作为 prefix 的一部分)  |
  | 时间条件注入      | MLP 混合 (action_time_mlp)      | adaRMSNorm (自适应 RMS 归一化) |
  | 最大 token 长度 | 48                            | 200                      |
  | 动作专家配置      | 不使用 adaRMS                    | 使用 adaRMS 注入流匹配时间步       |
  | 开放世界泛化      | 基线性能                          | 更好 (通过知识隔离训练)            |

  数据流详解

  1. 前缀编码 - embed_prefix()

  # src/openpi/models/pi0.py:106-137
  输入: Observation
  ├─ Images: 3 个相机视角 (224×224×3)
  ├─ Language: tokenized_prompt (最多 200 tokens)
  └─ State: (32-dim) - 在 π₀.₅ 中作为语言标记

  处理流程:
  1. SigLIP 编码每个图像 → image_tokens
  2. PaliGemma LLM 嵌入语言标记 → tokenized_inputs
  3. 图像和语言标记完全注意 (full attention between image and language)
  4. 拼接所有 tokens → prefix_tokens

  2. 后缀编码 - embed_suffix()

  # src/openpi/models/pi0.py:140-186
  输入: noisy_actions, timestep

  处理流程:
  1. Action 投影: Linear(action_dim, width) → action_tokens
  2. 时间嵌入: posemb_sincos(timestep) → time_emb
  3. **时间 MLP** (π₀.₅ 特点):
     - time_mlp_in: Linear(width, width)
     - Swish 激活
     - time_mlp_out: Linear(width, width)
     - Swish 激活
  4. **adaRMS 条件**: adarms_cond = time_emb (用于动作专家)
  5. 动作标记因果自回归 (causal attention)

  3. 流匹配训练

  # src/openpi/models/pi0.py:189-214
  损失计算:
  1. 采样时间步: time ~ Beta(1.5, 1) * 0.999 + 0.001
  2. 构造噪声状态: x_t = time * noise + (1-time) * actions
  3. 计算目标速度场: u_t = noise - actions
  4. 前向传播: v_t = model(x_t, time, observation)
  5. MSE 损失: mean((v_t - u_t)²)

  4. 推理采样

  # src/openpi/models/pi0.py:217-279
  Flow Matching 采样 (ODE Solver):
  1. 初始化: x_T ~ N(0, I), time = 1.0
  2. 迭代去噪 (num_steps 步):
     - 计算速度场: v_t = model(x_t, time)
     - 更新状态: x_{t-1} = x_t - dt * v_t (dt = 1/num_steps)
     - 更新时间: time ← time - dt
  3. 输出: x_0 (预测的动作序列)

  配置示例

  基础配置 (pi0_config.py:18-53):
  Pi0Config(
      dtype="bfloat16",
      paligemma_variant="gemma_2b",        # PaliGemma 专家
      action_expert_variant="gemma_300m",  # 动作专家
      action_dim=32,
      action_horizon=50,
      max_token_len=200,  # π₀.₅: 200, π₀: 48
      pi05=True,  # 启用 π₀.₅ 模式
      discrete_state_input=True,  # 状态作为离散标记
  )

  预训练检查点

  | 模型          | 用途        | 检查点路径                                      |
  |-------------|-----------|--------------------------------------------|
  | π₀.₅-Base   | 微调基础模型    | gs://openpi-assets/checkpoints/pi05_base   |
  | π₀.₅-LIBERO | LIBERO 基准 | gs://openpi-assets/checkpoints/pi05_libero |
  | π₀.₅-DROID  | DROID 数据集 | gs://openpi-assets/checkpoints/pi05_droid  |

  核心创新点

  1. 知识隔离: 通过特殊训练策略提升开放世界泛化
  2. adaRMSNorm: 自适应归一化，将流匹配时间步注入动作专家层
  3. 离散状态表示: 将状态作为语言标记处理，而非连续后缀 token
  4. 双专家架构: 分离语言理解和动作预测，提升专门化性能

  文件位置

  - 配置: src/openpi/models/pi0_config.py:18-110
  - 模型实现: src/openpi/models/pi0.py:66-280
  - PyTorch 版本: src/openpi/models_pytorch/pi0_pytorch.py
  - 训练配置: src/openpi/training/config.py (搜索 pi05_)

  这个架构设计使得 π₀.₅ 在保持 π₀ 的流匹配框架优势的同时，通过更精细的状态表示和条件注入机制实现了更好的泛化性能。
```
