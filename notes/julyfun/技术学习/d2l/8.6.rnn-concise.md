## nn.RNN

接口很简单：

```py
num_hiddens = 256
# RNN() 内部含有 W, b 参数之类的
rnn_layer = nn.RNN(len(vocab), num_hiddens)

# X.shape = [时间步，批量，词典大小(独热)]
# state 的形状你不用管，下次记得输入进去就行
Y, state = self.rnn(X, state)
# Y.shape = [时间步，批量，隐藏单元数]
```

其实 state 的形状可由此看出：

```py
def begin_state(self, device, batch_size=1):
    if not isinstance(self.rnn, nn.LSTM):
        # nn.GRU以张量作为隐状态
        return  torch.zeros((self.num_directions * self.rnn.num_layers,
                             batch_size, self.num_hiddens),
                            device=device)
```

注意隐状态 `state` 是在 RNN 对象之外另开对象进行存储的。

> 32:07
