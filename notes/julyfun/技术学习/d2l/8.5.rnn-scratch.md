## 梯度裁剪

类似于球形投影，使梯度的 L2 范数不超过阈值。

## 训练

注意训练时候每个批量的隐状态是分别存储的，不会相互影响。

- 多久一次 backward？
    - 要将一个批量内所有样本的所有时间步（在程序开始时设定，比如样本 size = 32，单次输入时间步为 35）forward 以后（每次 forward 仅进行一个时间步的预测），才进行 backward。因此权重参数矩阵会累乘，容易导致梯度爆炸，故进行梯度裁剪。d2l 代码中，梯度裁剪在 backward 后，updater 之前执行。
    - 注意对每个批量而言，每次输入仅有一个 token，并非多个时间步 token 同时输入。

## 手绘

![](https://telegraph-image-bhi.pages.dev/file/7bb171650762db0c7b678.jpg)

> 2:15:13
