## 梯度裁剪

类似于球形投影，使梯度的 L2 范数不超过阈值。

## 训练

注意训练时候每个批量的隐状态是分别存储的，不会相互影响。

- 多久一次 backward？每次要将一个批量内样本的单次输入所有时间步（在程序开始时设定，比如样本 size = 32，单次输入时间步为 35）forward 以后（每次 forward 仅进行一个时间步的预测），才进行 backward。因此权重参数矩阵会累乘，容易导致梯度爆炸，故进行梯度裁剪。

```py
for X, Y in seq_data_iter_sequential(my_seq, batch_size=2, num_steps=5):
    print('X: ', X, '\nY:', Y)
```

```
X:  tensor([[ 2,  3,  4,  5,  6],
        [18, 19, 20, 21, 22]])
Y: tensor([[ 3,  4,  5,  6,  7],
        [19, 20, 21, 22, 23]])
X:  tensor([[ 7,  8,  9, 10, 11],
        [23, 24, 25, 26, 27]])
Y: tensor([[ 8,  9, 10, 11, 12],
        [24, 25, 26, 27, 28]])
X:  tensor([[12, 13, 14, 15, 16],
        [28, 29, 30, 31, 32]])
Y: tensor([[13, 14, 15, 16, 17],
        [29, 30, 31, 32, 33]])
```

## 手绘

![](https://telegraph-image-bhi.pages.dev/file/7bb171650762db0c7b678.jpg)

> 2:15:13
