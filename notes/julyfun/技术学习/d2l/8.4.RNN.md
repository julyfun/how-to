## RNN 基础模型

$$bold(H)^(in n times h)_t = phi(bold(X^(in n times d "输入维度")) bold(W_(x h)^(in d times h)) + bold(H)_(t - 1)^(in h times h) bold(W)_(h h)^(in h times h) b_h)$$

$$O_t = H_t W_(h q "输出维度") + b_q$$

这里 $H_t$ 极其类似于单隐藏层感知机中的隐藏层，只是前一刻的隐藏层输出会成为下一刻隐藏层的输入。

## Perplexity 困惑度

$$exp(- 1 / n sum_(t = 1)^(n) log P(x_t | x_(t - 1), ..., x_1))$$

可以直接利用神经网络输出的概率，评估它有多自信。当每个输出的概率均为 $1$ 时，困惑度为 $1$，当概率为 $0$ 时困惑度正无穷，当概率为均匀分布时困惑度为唯一词元数（也是未压缩情况下存储序列最好的编码方式）。看到一个语言模型报告其 perplexity 为 $109$ 时，直观理解为它每次输出认为有 $109$ ge
