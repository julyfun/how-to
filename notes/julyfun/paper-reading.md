## 12.25

- RDT: https://github.com/thu-ml/RoboticsDiffusionTransformer
- 24.10.31 pi0: https://www.physicalintelligence.company/blog/pi0
- ALOHA + ACT: https://github.com/tonyzhaozh/act
- OpenVLA: https://github.com/openvla/openvla
- octo Open-Source Generalist Robot Policy: https://octo-models.github.io/

- 2023 具身智能 survey: https://eai-vc.github.io/

## 11.27

- Egomimic - RGB + handpose pretrain
    - https://egomimic.github.io/
- Dart: Vision Pro 纯虚拟环境收集数据
- 再看看 Pi0: 网络不适应夹爪，最后阶段 fine tune 一下
    - 夹爪 prompt?

## 11.20

- 清华的具身大模型: https://rdt-robotics.github.io/rdt-robotics/
    - https://arxiv.org/html/2410.07864?_immersive_translate_auto_translate=1
    - 视觉模型 Sig
- 跨具身模型 RTX 数据集: https://robotics-transformer-x.github.io/
    - 数据集下载: https://blog.csdn.net/qq_47572336/article/details/133592256?spm=1001.2014.3001.5502

## 11.18

- [ ] Diffusion 原理简述 (建议配合 GPT): https://www.mindspore.cn/tutorials/zh-CN/r2.4.0/generative/diffusion.html 
- opencv-python 功能列表: https://opencv-python-tutorials.readthedocs.io/zh/latest/4.%20OpenCV%E4%B8%AD%E7%9A%84%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/4.5.%20%E5%BD%A2%E6%80%81%E5%8F%98%E6%8D%A2/
                                     
## 11.16

- Diffusion 生成 Floor Plan. https://arxiv.org/pdf/2410.11908v1
- https://github.com/luozn15/FloorplanGAN/blob/master/RPlan_EDA.ipynb
- Floor layout GAN: https://dl.acm.org/doi/abs/10.1145/3570991.3571057

## 11.13

- UMI pretrain 单一夹爪泛化 action: https://umi-gripper.github.io/
- fastumi: https://fastumi.com/
- 差不多的: https://robotutilitymodels.com/
- robot data scailing laws: https://data-scaling-laws.github.io/

## 11.6

- [ ] #[hand, rgb] RGB 重建手部 mesh: https://github.com/geopavlakos/hamer

## 10.29

- [ ] https://arxiv.org/abs/2404.08636: 探索大模型的 3D 泛化识别 Probing the 3D Awareness of Visual Foundation Models


## 10.26

- [x] 形同我写的 IK 的 RelexedIK 2018: https://m.roboticsproceedings.org/rss14/p43.pdf
    - 优化用 scipy slsqp

## 10.19

- [ ] 无 teleoperation 的 mocap 灵巧数据采集: https://dex-cap.github.io/
    - 手部数据采集用的是电磁场手套
 
