---
https://www.bilibili.com/video/BV1QxB9YuERU
RT1
date: 2025-05-01 18:31:22
title: 具身智能大模型简介
tags: []
---
    - Transfromer 出轨迹
    - 3Hz inference
    - 实验：
        - 结合仿真数据训练或者其他机械臂的数据训练，也可以学到新技能.
        - 少一点数据，训练效果会如何变化？
            - 多样性减少的影响更大!
- RT2:
    - Use pretrained VLM. (PaLI-X, PaLM-E)
    - vision language + action Co-finetune.
    - Co-finetune how:
        - Input:
            - ViT
            - Language model
        - Output:
            - sometimes text [err?]
            - sometimes action
        - Inference 的时候只会 sample action token [?]
    - multi-TPU cloud inference
    - 在见过的任务上和 RT1 差不多
    - 没有结果的 task 上面，对世界知识的保留是非常好的.
    - 有 Emergence capability. 可从网络数据中迁移.
    - 参数数量影响结论:
        - Cofinetune 有更好的泛化性
        - 参数量大，泛化性强
    - 引入思维链可以解决很复杂的 command.
- RT-X:
    - 在 OpenX 数据上训练.
    - Trained on 9 manipulators.
    - 小规模数据训练上，超越原有模型.
    - 大规模数据训练上，RT-2-X 效果好.
        - 说明数据量大场景下需要高容量模型结构.
    - 跨具身形态训练，让模型从别的 domain 学到技能
    - 在输入中包含 image history 可以增强 generalization 性能
    - web-scale pretaining 重要 [?]
    - OXE (Open X Emb..) 非常 diverse 
- RT-H:
    - 考虑到有很多任务比较的动作序列比较像.
    - 思想: 加入 Language motion 中间层。输入任务后先预测移动指令（用语言描述）
        - 好处：多任务数据共享
    - Co-train: Internet data, action data & language motion data
    - Language motion 人类很容易干预，检查和纠正. 纠正也可以用于训练，比遥操作纠正效果更好.
    - 在新任务上需要很少的 correction.
    - 启示：lang-motion 可以 scale up 数据收集，可以压缩 action-space. 从而样本高效.
        - 但是对于复杂任务 lang-motion 可能比较复杂.
- OpenVLA
    - 训练数据集更大更 Diverse
    - Didn't use internet data, use only robot data.
    - 模型结构：
        - prethmetic VLM [?]
        - Input to => DINOv2 and SigLIP 融合到一起的 Vision Encoder.
            - Get spacial and high-level semantic feature.
        - outrput => Small 2-layer MLP projector.
            - Project to language token space [?]
        - => Llama2 7B language model
        - => Action De-tokenizer
            - 输出 action. (夹爪）
    - 性能实验:
        - OXE 上训练
        - out-of-the-box 直接泛化能力
        - 做了数据清洗
    - VLA Finetune 性能实验:
        - 发现 OpenVLA 在困难 diverse 多种 instructions 多物体任务上，比原来更好
        - 归结于 OpenX 的 pretraining.
    - Lora 实验:
        - LoRA 在性能保持上非常好！低资源 Finetune
    - 验证 memory-efficient
        - 4bit 量化可以将 GPU memory 减半，并保持差不多的性能
- [下面改进 action output]
    - problem:
        - policy 执行每一步都有可能与误差，会累积.
        - 同一个任务的方法是多峰的
    - 使用 action chunking
    - 使用生成式建模
- [idea] action chunking
    - 每一步我都预测后四步，然后做加权.
- [idea] 生成式建模
- [paper] ACT (Conditional Variational AutoEncoder)
    - ...todo
- [paper] Diffusion Policy
    - 表达多峰分布
    - high-dimensional, 可建模长 action 序列的分布
    - $p(A_t | O_t)$. VAE 的 condition 是 denoising iteration $k$ 和 observation features $O_t$. 生成的是 $A_t$.
- $pi_0$ 
    - PS:
        - 整个架构是 transfusion
    - 基于 Pretrain 的 VLM PaliGemma
        - 用 SIGLIP 作为 vision-encoder
        - gemma 是 lang model
    - 动作生成用的也是 Flow-matching
    - Training recipe:
        - Pretraining: 让模型见到各种各样的 task & behaviors
        - Post-training: 更高质量的目标任务的数据
        - OXE, Bridge v2, DROID
        - 为了适应不同机器人维度，使用最大维度的 configuration vector 和 action vector 来训练。
            - 对于较小维度机器人，直接 zero-pad
            - "mask out the missing image slots"
    - Pretraining 对长程和困难任务很重要.
- RDT:
    - 基于 Diffusion-transformer
    - Data scarcity: 目标任务上数量少？考虑在 cross-embodiment 做大量 Pretrain
    - 数据集结构不一样: 提出 unified space
    - Input: 图片，lang instruction，本体感知，控制频率
        - Image 通过 SIGLIP (frozen)
        - lang: T5XXL [?] (frozen)
    - 随机且独立地 mask 某一个多模态的输入，防止过度依赖某一个模态
    - Training recipe:
        - Unified action space
        - Pre-train 巨大数据集
        - 自己 finetune 高质量数据集
            - 6K 轨迹，300 任务，instruction (GPT4输出以增加多样性)，物体和环境多样性
    - 效果:
        - zero-shot 到没有见过的任务.
        - few-shot 学会新技能.
        - 可以遥控机器狗.
        - 模型大小，数据量大小和 Diffusion 都对于 RDT 性能关键.
- GR-2 字节提出的模型
    - 先做大量 text-video pre-training
    - 然后再 video-action co-training（下游 finetune）
    - 结构:
        - Text: CLIP
        - Image: VQGAN
        - backbone: GPT-style
        - action traj: action chunk + CVAE
    - [idea] Video generation as planner!
        - 实验证明视频预测和真实执行非常吻合.
    
## Takeaways 思考
- 大量 pre-training 然后在高质量数据集上 finetune 可以提升性能.
- Cross-embodiment 训练可以增强领域迁移能力。
- VLA 带来世界知识和推理能力
- action chunking & generative models (better than single step auto-regressive)
## Limitation
- Imitation Learning 无法超越示教者的表现.
- Generalization 还是不够. 主要是没有见过的动作和没有见过的具身形态.
- 跨具身形态和训练可以改进. (see HPT 凯明组)
## Future work
- 如何从人类视频中学习新的 skill
- Pretraining datasets 如何构成.
- 需要什么样的数据，多少数据才能 near-perfect.
- 需要多 diverse.
- 构建很大很高质量的数据集，高效训练方法和数据来源.
- 继续构建 VLA foundation model.
- 考虑使用 simulation data. 目前做的不多.
- 考虑使用强化学习.
