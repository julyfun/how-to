---
title: "RDP"
date: 2026-01-20 19:09:53
tags: ["26", "01"]
author: "julyfun arch y9000p"
os: "Linux archfun 6.18.5-arch1-1 #1 SMP PREEMPT_DYNAMIC Sun, 11 Jan 2026 17:10:53 +0000 x86_64 GNU/Linux"
assume-you-know: [computer]
confidence: 2
---

```
  ┌─────────────────────────────────────────────────────────────────────────────────────┐
  │                           TRAINING FLOW                                              │
  ├─────────────────────────────────────────────────────────────────────────────────────┤
  │                                                                                     │
  │  原始数据 (24fps)                                                                    │
  │  ├── 图像 (slow): external_camera, left_wrist_camera                               │
  │  ├── 触觉/力 (fast): left_gripper2_marker_offset_emb, tcp_pose, gripper_width       │
  │  └── 动作: (x, y, z, gripper_width) 相对增量                                        │
  │                                                                                     │
  └─────────────────────────────────────────────────────────────────────────────────────┘
                                     │
                                     ▼
  ┌─────────────────────────────────────────────────────────────────────────────────────┐
  │  Dataset 输出 (real_image_tactile_dataset.py:210-278)                               │
  ├─────────────────────────────────────────────────────────────────────────────────────┤
  │                                                                                     │
  │  key_first_k = n_obs_steps * obs_temporal_downsample_ratio = 2 * 2 = 4              │
  │                                                                                     │
  │  ┌─────────────────┐  ┌─────────────────────────┐  ┌───────────────────────────┐  │
  │  │ obs (图像)      │  │ extended_obs (触觉)      │  │ action                    │  │
  │  │                 │  │                         │  │                           │  │
  │  │ 取 4 帧,         │  │ horizon=32 帧            │  │ horizon=32 帧              │  │
  │  │ 下采样到 2 帧    │  │ 不下采样                 │  │ 不下采样                   │  │
  │  │                 │  │                         │  │                           │  │
  │  │ (B,2,3,240,320) │  │ (B,32,15)               │  │ (B,32,4)                  │  │
  │  └─────────────────┘  └─────────────────────────┘  └───────────────────────────┘  │
  │                                                                                     │
  └─────────────────────────────────────────────────────────────────────────────────────┘
                                     │
                                     ▼
  ┌─────────────────────────────────────────────────────────────────────────────────────┐
  │  Training Step (latent_diffusion_unet_image_policy.py:213-280)                      │
  ├─────────────────────────────────────────────────────────────────────────────────────┤
  │                                                                                     │
  │  ┌──────────────────────────────────────────────────────────────────────────────┐  │
  │  │  1. 归一化                                                                     │  │
  │  │     nobs = (B, 2, 3, 240, 320)                                                │  │
  │  │     nactions = (B, 32, 4)                                                     │  │
  │  └──────────────────────────────────────────────────────────────────────────────┘  │
  │                                      │                                              │
  │                                      ▼                                              │
  │  ┌──────────────────────────────────────────────────────────────────────────────┐  │
  │  │  2. VAE Encoder (获取 latent action)                                          │  │
  │  │     nactions → preprocess → (B, 128)                                         │  │
  │  │     EncoderCNN → (B, 2, 4)  [horizon=32 下采样到 2]                          │  │
  │  │     quant_state_without_vq → (B, 16)  [n_embed=16]                           │  │
  │  │     rearrange → nlatent_actions = (B, 2, 16)                                 │  │
  │  └──────────────────────────────────────────────────────────────────────────────┘  │
  │                                      │                                              │
  │                                      ▼                                              │
  │  ┌──────────────────────────────────────────────────────────────────────────────┐  │
  │  │  3. Obs Encoder (获取图像特征)                                               │  │
  │  │     nobs (B, 2, 3, 240, 320) → reshape (B*2, 3, 240, 320)                    │  │
  │  │     MultiImageObsEncoder (ResNet18) → (B*2, 512)                            │  │
  │  │     reshape → global_cond = (B, 1024)                                        │  │
  │  └──────────────────────────────────────────────────────────────────────────────┘  │
  │                                      │                                              │
  │                                      ▼                                              │
  │  ┌──────────────────────────────────────────────────────────────────────────────┐  │
  │  │  4. Diffusion Training                                                        │  │
  │  │     trajectory = nlatent_actions = (B, 2, 16)                                │  │
  │  │     加噪声: noisy_trajectory = scheduler.add_noise(trajectory, noise, t)    │  │
  │  │     预测噪声: pred = Unet1D(noisy_trajectory, t, global_cond)                │  │
  │  │     Loss: MSE(pred, noise)                                                   │  │
  │  └──────────────────────────────────────────────────────────────────────────────┘  │
  │                                                                                     │
  └─────────────────────────────────────────────────────────────────────────────────────┘

  ---
  推理流程

  ┌─────────────────────────────────────────────────────────────────────────────────────┐
  │                           INFERENCE FLOW                                             │
  ├─────────────────────────────────────────────────────────────────────────────────────┤
  │                                                                                     │
  │  推理频率: inference_fps = 2 Hz (每 500ms 一次)                                     │
  │  控制频率: control_fps = 24 Hz (每 41.67ms 一次)                                    │
  │                                                                                     │
  └─────────────────────────────────────────────────────────────────────────────────────┘
                                     │
                                     ▼
  ┌─────────────────────────────────────────────────────────────────────────────────────┐
  │  Step 1: 获取观测 (real_runner.py:462-484)                                          │
  ├─────────────────────────────────────────────────────────────────────────────────────┤
  │                                                                                     │
  │  obs = env.get_obs(obs_steps=2, temporal_downsample_ratio=2)                        │
  │                                                                                     │
  │  ┌─────────────────┐                                                               │
  │  │ obs_dict        │                                                               │
  │  │                 │   从 24fps 原始数据                                            │
  │  │ (1, 2, 3, 240, 320)  → 取 4 帧, 下采样到 2 帧 (12fps)                           │
  │  │                 │                                                               │
  │  │ external_camera │                                                               │
  │  │ left_wrist_...  │   注意: 这里只包含 slow 观测 (图像)                            │
  │  └─────────────────┘                                                               │
  │                                                                                     │
  └─────────────────────────────────────────────────────────────────────────────────────┘
                                     │
                                     ▼
  ┌─────────────────────────────────────────────────────────────────────────────────────┐
  │  Step 2: Policy 推理 (latent_diffusion_unet_image_policy.py:88-174)                 │
  ├─────────────────────────────────────────────────────────────────────────────────────┤
  │                                                                                     │
  │  ┌──────────────────────────────────────────────────────────────────────────────┐  │
  │  │  2.1 归一化 & 编码观测                                                        │  │
  │  │      nobs (1, 2, 3, 240, 320)                                                 │  │
  │  │      ObsEncoder → (1, 1024) global_cond                                       │  │
  │  └──────────────────────────────────────────────────────────────────────────────┘  │
  │                                      │                                              │
  │                                      ▼                                              │
  │  ┌──────────────────────────────────────────────────────────────────────────────┐  │
  │  │  2.2 Diffusion 采样 (DDIM, 100 steps)                                         │  │
  │  │      初始: trajectory ~ N(0, I), shape=(1, 2, 16)                             │  │
  │  │      for t in [999, ..., 0]:                                                 │  │
  │  │          pred_noise = Unet1D(trajectory, t, global_cond)                      │  │
  │  │          trajectory = scheduler.step(pred_noise, t, trajectory)              │  │
  │  │      输出: nlatent_sample = (1, 2, 16)                                        │  │
  │  └──────────────────────────────────────────────────────────────────────────────┘  │
  │                                      │                                              │
  │                                      ▼                                              │
  │  ┌──────────────────────────────────────────────────────────────────────────────┐  │
  │  │  2.3 反归一化 & 处理 latent action                                            │  │
  │  │      nlatent_sample (1, 2, 16) → unnormalize                                 │  │
  │  │      rearrange → (1, 32)                                                      │  │
  │  │      post_quant → state_vq (1, 32)                                           │  │
  │  │                                                                               │  │
  │  │  当 return_latent_action=True:                                                │  │
  │  │      action_pred = state_vq.unsqueeze(1).expand(1, 32, 32) → (1, 32, 32)     │  │
  │  │      这里的 action 是 latent action!                                          │  │
  │  └──────────────────────────────────────────────────────────────────────────────┘  │
  │                                                                                     │
  │  输出: action = (1, 16, 32)  ← 16 步 latent action, 每步是 32 维                     │
  │        action_pred = (1, 32, 32)  ← 完整 32 步 latent action                        │
  │                                                                                     │
  └─────────────────────────────────────────────────────────────────────────────────────┘
                                     │
                                     ▼
  ┌─────────────────────────────────────────────────────────────────────────────────────┐
  │  Step 3: Temporal Ensemble Buffer (real_runner.py:500-516)                          │
  ├─────────────────────────────────────────────────────────────────────────────────────┤
  │                                                                                     │
  │  将预测的 latent action 添加到 buffer，并添加时间戳:                                 │
  │                                                                                     │
  │  action_all = (16, 32) latent action                                                │
  │  action_with_timestamp = (16, 33)  ← 添加 step 索引                                │
  │                                                                                     │
  │  分离为 TCP 和 Gripper 部分                                                          │
  │  tcp_ensemble_buffer.add(tcp_latent_action, step)                                   │
  │  gripper_ensemble_buffer.add(gripper_latent_action, step)                           │
  │                                                                                     │
  └─────────────────────────────────────────────────────────────────────────────────────┘
                                     │
                                     ▼
  ┌─────────────────────────────────────────────────────────────────────────────────────┐
  │  Step 4: 高频解码 & 执行 (real_runner.py:293-383)                                   │
  ├─────────────────────────────────────────────────────────────────────────────────────┤
  │                                                                                     │
  │  每 41.67ms (24Hz) 执行一次:                                                         │
  │                                                                                     │
  │  ┌──────────────────────────────────────────────────────────────────────────────┐  │
  │  │  4.1 从 buffer 获取 latent action                                              │  │
  │  │      tcp_step_latent = (16,)  ← 从 ensemble 获取                               │  │
  │  │      gripper_step_latent = (16,)                                              │  │
  │  └──────────────────────────────────────────────────────────────────────────────┘  │
  │                                      │                                              │
  │                                      ▼                                              │
  │  ┌──────────────────────────────────────────────────────────────────────────────┐  │
  │  │  4.2 获取 Fast 观测 (触觉)                                                     │  │
  │  │      extended_obs = env.get_obs(step=7, temporal_downsample_ratio=2)          │  │
  │  │      触觉数据: (B, 16, 15)  ← 根据对应 step 获取                               │  │
  │  └──────────────────────────────────────────────────────────────────────────────┘  │
  │                                      │                                              │
  │                                      ▼                                              │
  │  ┌──────────────────────────────────────────────────────────────────────────────┐  │
  │  │  4.3 VAE Decoder 解码 (predict_from_latent_action)                            │  │
  │  │      latent (1, 16) + temporal_cond (触觉)                                   │  │
  │  │      → DecoderRNN → action (1, 32, 4)                                         │  │
  │  │                                                                               │  │
  │  │  注意: 这里才使用 fast observation (触觉)!                                    │  │
  │  └──────────────────────────────────────────────────────────────────────────────┘  │
  │                                      │                                              │
  │                                      ▼                                              │
  │  ┌──────────────────────────────────────────────────────────────────────────────┐  │
  │  │  4.4 执行单个动作                                                              │  │
  │  │      step_action = action[0][-1]  ← 取最后一步 (4维)                           │  │
  │  │      env.execute_action(step_action)                                          │  │
  │  └──────────────────────────────────────────────────────────────────────────────┘  │
  │                                                                                     │
  └─────────────────────────────────────────────────────────────────────────────────────┘
```

